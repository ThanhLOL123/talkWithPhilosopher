# Deep Researcher Agent + Chat Agent - Philosopher AI System ğŸ§ ğŸ’¬

Má»™t há»‡ thá»‘ng AI Agent tiÃªn tiáº¿n káº¿t há»£p **Deep Research Agent** vÃ  **Chat Agent** Ä‘á»ƒ nghiÃªn cá»©u toÃ n diá»‡n cÃ¡c triáº¿t gia vÃ  sau Ä‘Ã³ trÃ² chuyá»‡n trá»±c tiáº¿p vá»›i há». Há»‡ thá»‘ng sá»­ dá»¥ng LangGraph, Groq/OpenRouter LLM, vÃ  Tavily Search Ä‘á»ƒ táº¡o ra tráº£i nghiá»‡m há»c táº­p triáº¿t há»c tÆ°Æ¡ng tÃ¡c hoÃ n toÃ n má»›i.

## âœ¨ TÃ­nh nÄƒng chÃ­nh

### ğŸ” Deep Research Agent
- **NghiÃªn cá»©u tá»± Ä‘á»™ng**: Chá»‰ cáº§n tÃªn triáº¿t gia, agent tá»± Ä‘á»™ng xÃ¡c Ä‘á»‹nh cÃ¡c khÃ­a cáº¡nh cáº§n nghiÃªn cá»©u
- **TÃ¬m kiáº¿m thÃ´ng minh**: Tá»± Ä‘á»™ng táº¡o vÃ  thá»±c hiá»‡n cÃ¡c truy váº¥n tÃ¬m kiáº¿m tá»‘i Æ°u dá»±a trÃªn 8 háº¡ng má»¥c nghiÃªn cá»©u triáº¿t há»c
- **TrÃ­ch xuáº¥t thÃ´ng tin cÃ³ cáº¥u trÃºc**: PhÃ¢n tÃ­ch vÃ  tá»• chá»©c thÃ´ng tin tá»« nhiá»u nguá»“n
- **Tá»•ng há»£p tri thá»©c**: Táº¡o ra há»“ sÆ¡ triáº¿t gia toÃ n diá»‡n vÃ  máº¡ch láº¡c

### ğŸ’¬ Chat Agent  
- **TrÃ² chuyá»‡n thá»±c táº¿**: Chuyá»ƒn Ä‘á»•i há»“ sÆ¡ nghiÃªn cá»©u thÃ nh chatbot triáº¿t gia cÃ³ tÃ­nh cÃ¡ch riÃªng
- **Roleplay thÃ´ng minh**: Agent tá»± táº¡o prompt roleplay dá»±a trÃªn thÃ´ng tin Ä‘Ã£ nghiÃªn cá»©u
- **Lá»‹ch sá»­ cuá»™c trÃ² chuyá»‡n**: Duy trÃ¬ ngá»¯ cáº£nh vÃ  tÃ­nh nháº¥t quÃ¡n trong cuá»™c trÃ² chuyá»‡n
- **Phong cÃ¡ch Ä‘áº·c trÆ°ng**: MÃ´ phá»ng phong cÃ¡ch láº­p luáº­n vÃ  ngÃ´n ngá»¯ cá»§a tá»«ng triáº¿t gia

### ğŸŒ Giao diá»‡n Ä‘a dáº¡ng
- **Streamlit Web App**: Giao diá»‡n web hiá»‡n Ä‘áº¡i, thÃ¢n thiá»‡n vá»›i ngÆ°á»i dÃ¹ng
- **Command Line Interface**: Cho nhá»¯ng ai thÃ­ch sá»­ dá»¥ng terminal
- **Xá»­ lÃ½ Ä‘a ngÃ´n ngá»¯**: Há»— trá»£ tiáº¿ng Viá»‡t vÃ  tiáº¿ng Anh
- **LÆ°u trá»¯ káº¿t quáº£**: Xuáº¥t bÃ¡o cÃ¡o dÆ°á»›i Ä‘á»‹nh dáº¡ng JSON

## ğŸ—ï¸ Cáº¥u trÃºc dá»± Ã¡n

```
philosopher_research_project/
â”œâ”€â”€ .env                          # File biáº¿n mÃ´i trÆ°á»ng (táº¡o tá»« .env_example)
â”œâ”€â”€ requirements.txt              # Danh sÃ¡ch thÆ° viá»‡n cáº§n thiáº¿t
â”œâ”€â”€ main.py                       # á»¨ng dá»¥ng Streamlit chÃ­nh
â”œâ”€â”€ README.md                     # HÆ°á»›ng dáº«n sá»­ dá»¥ng
â”œâ”€â”€ research_*.json              # Káº¿t quáº£ nghiÃªn cá»©u máº«u (Karl Marx, Wittgenstein, Socrates)
â”‚
â”œâ”€â”€ research_agent/              # Package Research Agent
â”‚   â”œâ”€â”€ __init__.py             # Khá»Ÿi táº¡o package
â”‚   â”œâ”€â”€ state.py                # Äá»‹nh nghÄ©a state structure vÃ  8 categories
â”‚   â”œâ”€â”€ llm_services.py         # Cáº¥u hÃ¬nh LLM (OpenRouter/Groq)
â”‚   â”œâ”€â”€ tool_services.py        # Cáº¥u hÃ¬nh tools (Tavily Search)
â”‚   â”œâ”€â”€ nodes.py                # Logic chi tiáº¿t cho tá»«ng node (443 dÃ²ng)
â”‚   â””â”€â”€ graph.py                # Äá»‹nh nghÄ©a LangGraph workflow
â”‚
â”œâ”€â”€ chatAgent/                   # Package Chat Agent
â”‚   â”œâ”€â”€ __init__.py             # Khá»Ÿi táº¡o package
â”‚   â”œâ”€â”€ main_chat.py            # CLI interface cho chat agent
â”‚   â”œâ”€â”€ chat_state.py           # State management cho chat
â”‚   â”œâ”€â”€ chat_graph.py           # LangGraph workflow cho chat
â”‚   â”œâ”€â”€ chat_nodes.py           # Nodes logic cho chat workflow
â”‚   â”œâ”€â”€ chat_llm_services.py    # LLM config cho chat
â”‚   â”œâ”€â”€ chat_prompt_loader.py   # Load roleplay prompt tá»« file
â”‚   â”œâ”€â”€ processInformation.py   # Xá»­ lÃ½ thÃ´ng tin nghiÃªn cá»©u thÃ nh roleplay prompt
â”‚   â””â”€â”€ prompt.py               # File chá»©a roleplay prompt Ä‘Æ°á»£c táº¡o tá»± Ä‘á»™ng
â”‚
â””â”€â”€ .venv/                       # Virtual environment
    __pycache__/                 # Python cache files
    .git/                        # Git repository
    chat_checkpoints.sqlite*     # LangGraph chat history database
```

## ğŸš€ CÃ i Ä‘áº·t vÃ  Thiáº¿t láº­p

### 1. Clone repository vÃ  cÃ i Ä‘áº·t dependencies

```bash
# Clone repository (náº¿u cÃ³)
git clone <repository-url>
cd philosopher-ai-system

# Táº¡o virtual environment (khuyáº¿n khÃ­ch)
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# hoáº·c
.venv\Scripts\activate     # Windows

# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt
```

### 2. Thiáº¿t láº­p API Keys

Táº¡o file `.env` vá»›i ná»™i dung sau:

```env
# API Keys - Báº®T BUá»˜C
GROQ_API_KEY="your_groq_api_key_here"
TAVILY_API_KEY="your_tavily_api_key_here"

# TÃ™Y CHá»ŒN: OpenRouter (náº¿u muá»‘n dÃ¹ng thay cho Groq)
OPENROUTER_API_KEY="your_openrouter_api_key_here" 

# TÃ™Y CHá»ŒN: Chá»‰ Ä‘á»‹nh model cá»¥ thá»ƒ
GROQ_MODEL_NAME="mixtral-8x7b-32768"
# OPENROUTER_MODEL_NAME="anthropic/claude-3-haiku"
```

#### ğŸ“‹ HÆ°á»›ng dáº«n láº¥y API Keys:

**ğŸ¤– Groq API Key** (MIá»„N PHÃ - Khuyáº¿n khÃ­ch):
1. Truy cáº­p [GroqCloud Console](https://console.groq.com/keys)
2. ÄÄƒng kÃ½/Ä‘Äƒng nháº­p tÃ i khoáº£n
3. Táº¡o API key má»›i
4. Copy vÃ  paste vÃ o file `.env`

**ğŸ” Tavily API Key** (MIá»„N PHÃ tier cÃ³ sáºµn):
1. Truy cáº­p [Tavily.com](https://tavily.com/)  
2. ÄÄƒng kÃ½ tÃ i khoáº£n vÃ  táº¡o API key
3. Copy vÃ  paste vÃ o file `.env`

**ğŸŒ OpenRouter API Key** (TÃ¹y chá»n):
1. Truy cáº­p [OpenRouter.ai](https://openrouter.ai/)
2. ÄÄƒng kÃ½ vÃ  táº¡o API key (cáº§n thanh toÃ¡n cho má»™t sá»‘ model)

### 3. Kiá»ƒm tra cÃ i Ä‘áº·t

```bash
# Kiá»ƒm tra dependencies
python -c "import langchain, langgraph, streamlit; print('Dependencies OK')"

# Kiá»ƒm tra API keys
python -c "from dotenv import load_dotenv; import os; load_dotenv(); print('Groq:', bool(os.getenv('GROQ_API_KEY'))); print('Tavily:', bool(os.getenv('TAVILY_API_KEY')))"
```

## ğŸ® CÃ¡ch sá»­ dá»¥ng

### ğŸŒ PhÆ°Æ¡ng phÃ¡p 1: Streamlit Web App (Khuyáº¿n khÃ­ch)

```bash
streamlit run main.py
```

Sau Ä‘Ã³ má»Ÿ trÃ¬nh duyá»‡t táº¡i `http://localhost:8501`

**Giao diá»‡n web bao gá»“m 2 tab:**

1. **ğŸ” Deep Research Agent**: 
   - Nháº­p tÃªn triáº¿t gia (VD: "Plato", "Immanuel Kant", "Friedrich Nietzsche")
   - Báº¥m "Start Research" 
   - Xem káº¿t quáº£ nghiÃªn cá»©u theo 8 háº¡ng má»¥c
   - Download file JSON káº¿t quáº£

2. **ğŸ’¬ Chat With Philosopher**:
   - Sau khi research xong, báº¥m "Start Chat with this Philosopher"
   - Hoáº·c upload file JSON research cÃ³ sáºµn 
   - TrÃ² chuyá»‡n trá»±c tiáº¿p vá»›i triáº¿t gia

### ğŸ–¥ï¸ PhÆ°Æ¡ng phÃ¡p 2: Command Line Interface

**Research Agent:**
```bash
# Cháº¡y research tá»« terminal (cáº§n tÃ¹y chá»‰nh code)
python -c "
from research_agent.graph import get_default_research_graph
import json
graph = get_default_research_graph()
result = graph.invoke({'philosopher_name': 'Socrates'})
print(json.dumps(result, indent=2, ensure_ascii=False))
"
```

**Chat Agent:**  
```bash
# Cháº¡y chat CLI (cáº§n cÃ³ file prompt.py Ä‘Ã£ Ä‘Æ°á»£c táº¡o)
python chatAgent/main_chat.py
```

## ğŸ“Š 8 Háº¡ng má»¥c nghiÃªn cá»©u

Agent sáº½ tá»± Ä‘á»™ng nghiÃªn cá»©u triáº¿t gia theo 8 háº¡ng má»¥c chi tiáº¿t:

1. **ğŸ“– ThÃ´ng tin Tiá»ƒu sá»­ vÃ  Bá»‘i cáº£nh Lá»‹ch sá»­ - VÄƒn hÃ³a**
   - Tiá»ƒu sá»­ cÃ¡ nhÃ¢n, nÆ¡i sinh, thá»i Ä‘áº¡i
   - Bá»‘i cáº£nh lá»‹ch sá»­, vÄƒn hÃ³a, chÃ­nh trá»‹
   - MÃ´i trÆ°á»ng há»c thuáº­t vÃ  áº£nh hÆ°á»Ÿng sá»›m

2. **ï¿½ï¿½ CÃ¡c TÃ¡c pháº©m ChÃ­nh vÃ  Ná»™i dung Cá»‘t lÃµi**
   - Danh sÃ¡ch tÃ¡c pháº©m quan trá»ng
   - Ná»™i dung vÃ  má»¥c tiÃªu chÃ­nh cá»§a tá»«ng tÃ¡c pháº©m
   - Bá»‘i cáº£nh xuáº¥t báº£n vÃ  Ä‘Ã³ng gÃ³p Ä‘á»™c Ä‘Ã¡o

3. **ğŸ§  Há»c thuyáº¿t vÃ  TÆ° tÆ°á»Ÿng Triáº¿t há»c Cá»‘t lÃµi**
   - KhÃ¡i niá»‡m triáº¿t há»c trung tÃ¢m
   - Luáº­n Ä‘iá»ƒm vÃ  luáº­n cá»© chÃ­nh
   - Há»‡ thá»‘ng triáº¿t há»c tá»•ng thá»ƒ

4. **ğŸ¯ Quan Ä‘iá»ƒm vá» cÃ¡c Chá»§ Ä‘á» Triáº¿t há»c Cá»¥ thá»ƒ**
   - Thá»±c táº¡i vÃ  siÃªu hÃ¬nh há»c
   - Tri thá»©c luáº­n vÃ  phÆ°Æ¡ng phÃ¡p luáº­n
   - Äáº¡o Ä‘á»©c há»c vÃ  triáº¿t há»c chÃ­nh trá»‹
   - Tháº©m má»¹ há»c vÃ  cÃ¡c lÄ©nh vá»±c khÃ¡c

5. **ğŸ¤ Má»‘i quan há»‡ vÃ  TÆ°Æ¡ng tÃ¡c Triáº¿t há»c**
   - Triáº¿t gia áº£nh hÆ°á»Ÿng Ä‘áº¿n há»
   - Triáº¿t gia há» áº£nh hÆ°á»Ÿng Ä‘áº¿n
   - Cuá»™c tranh luáº­n vÃ  Ä‘á»‘i thoáº¡i quan trá»ng

6. **âš–ï¸ PhÃª bÃ¬nh vÃ  ÄÃ¡nh giÃ¡ Há»c thuyáº¿t**
   - Nhá»¯ng chá»‰ trÃ­ch chÃ­nh Ä‘á»‘i vá»›i há»c thuyáº¿t
   - Äiá»ƒm máº¡nh vÃ  Ä‘iá»ƒm yáº¿u Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh
   - Pháº£n bÃ¡c vÃ  biá»‡n há»™

7. **ğŸ”¬ PhÆ°Æ¡ng phÃ¡p Triáº¿t há»c Äáº·c trÆ°ng**
   - CÃ¡ch tiáº¿p cáº­n nghiÃªn cá»©u triáº¿t há»c
   - PhÆ°Æ¡ng phÃ¡p luáº­n Ä‘áº·c trÆ°ng
   - Phong cÃ¡ch láº­p luáº­n riÃªng biá»‡t

8. **âœï¸ Phong cÃ¡ch Láº­p luáº­n vÃ  VÄƒn phong**
   - HÃ¬nh thá»©c trÃ¬nh bÃ y (Ä‘á»‘i thoáº¡i, luáº­n vÄƒn, etc.)
   - Äáº·c Ä‘iá»ƒm tu tá»« há»c
   - Loáº¡i báº±ng chá»©ng vÃ  lÃ½ luáº­n sá»­ dá»¥ng

## ğŸ”§ Workflow chi tiáº¿t

### ğŸ” Research Agent Workflow

```mermaid
flowchart TD
    START([Báº¯t Ä‘áº§u vá»›i tÃªn triáº¿t gia]) --> A[Load Initial State]
    A --> B[Select Next Category]
    
    B --> C{CÃ²n category nÃ o?}
    
    C -->|CÃ³| D[Generate Queries for Category]
    C -->|KhÃ´ng| H[Synthesize Final Profile]
    
    D --> E[Tavily Search for Category]
    E --> F[Extract Information for Category]
    F --> G[Accumulate and Increment Category]
    G --> B
    
    H --> END([Káº¿t thÃºc - JSON Result])
    
    %% Styling
    classDef startEnd fill:#e1f5fe,stroke:#01579b,stroke-width:3px,color:#000
    classDef process fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px,color:#000
    classDef decision fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,color:#000
    classDef loop fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000
    classDef synthesis fill:#fff8e1,stroke:#f57f17,stroke-width:2px,color:#000
    
    class START,END startEnd
    class A,D,E,F process
    class C decision
    class B,G loop
    class H synthesis
```

### ğŸ’¬ Chat Agent Workflow

```mermaid
flowchart TD
    START2([Research JSON Input]) --> I[Process Information]
    I --> J[Generate Roleplay Prompt]
    J --> K[Load Chat Workflow]
    K --> L[Initialize Chat Session]
    L --> M[Chat Loop]
    M --> N{User Input?}
    N -->|CÃ³| O[Process User Message]
    N -->|"quit"| P([End Chat])
    O --> Q[Generate Response]
    Q --> R[Update Chat History]
    R --> M
    
    %% Styling  
    classDef startEnd fill:#e1f5fe,stroke:#01579b,stroke-width:3px,color:#000
    classDef process fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px,color:#000
    classDef decision fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,color:#000
    classDef chat fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000
    
    class START2,P startEnd
    class I,J,K,L,O,Q,R process
    class N decision
    class M chat
```

## ğŸ“ Káº¿t quáº£ vÃ  file output

### Research Results (JSON format)
```json
{
  "philosopher_name": "Plato",
  "final_synthesized_profile": {
    "Biographical_Historical_Context": {...},
    "Major_Works_Core_Content": {...},
    "Core_Philosophical_Doctrines_Ideas": {...},
    "Views_on_Specific_Philosophical_Topics": {...},
    "Philosophical_Relationships_Interactions": {...},
    "Critiques_Evaluations_of_Doctrines": {...},
    "Characteristic_Philosophical_Methodology": {...},
    "Argumentative_Style_Rhetoric": {...}
  },
  "total_generated_queries_count": 24,
  "total_search_results_count": 120,
  "accumulated_extracted_information": {...}
}
```

### Chat Session Database
- File: `chat_checkpoints.sqlite`
- LÆ°u trá»¯ lá»‹ch sá»­ cuá»™c trÃ² chuyá»‡n vá»›i LangGraph checkpoints
- Há»— trá»£ multiple chat sessions vá»›i thread_id unique

## âš™ï¸ TÃ¹y chá»‰nh nÃ¢ng cao

### ğŸ¤– Thay Ä‘á»•i LLM Models

**Groq Models** (trong `.env`):
```env
GROQ_MODEL_NAME="mixtral-8x7b-32768"     # Balanced (khuyáº¿n khÃ­ch)
# GROQ_MODEL_NAME="llama3-70b-8192"      # Powerful but slower  
# GROQ_MODEL_NAME="llama3-8b-8192"       # Fast but less capable
# GROQ_MODEL_NAME="gemma-7b-it"          # Alternative option
```

**OpenRouter Models** (trong `.env`):
```env
OPENROUTER_MODEL_NAME="anthropic/claude-3-haiku"
# OPENROUTER_MODEL_NAME="meta-llama/llama-3-8b-instruct"
# OPENROUTER_MODEL_NAME="mistralai/mixtral-8x7b-instruct"
```

### ğŸ” TÃ¹y chá»‰nh tÃ¬m kiáº¿m

Chá»‰nh sá»­a `research_agent/tool_services.py`:
```python
def get_default_search_tool() -> TavilySearchResults:
    return get_tavily_search_tool(max_results=8)  # TÄƒng tá»« 5 lÃªn 8
```

### ğŸ“ TÃ¹y chá»‰nh Categories nghiÃªn cá»©u

Chá»‰nh sá»­a `research_agent/state.py`:
```python
ALL_RESEARCH_CATEGORIES = [
    "Biographical_Historical_Context",
    "Major_Works_Core_Content", 
    # ThÃªm categories má»›i á»Ÿ Ä‘Ã¢y
    "Your_Custom_Category"
]
```

## ğŸ’¡ VÃ­ dá»¥ sá»­ dá»¥ng cá»¥ thá»ƒ

### VÃ­ dá»¥ 1: NghiÃªn cá»©u Immanuel Kant

1. Má»Ÿ Streamlit app: `streamlit run main.py`
2. Tab "Deep Research Agent" â†’ Nháº­p "Immanuel Kant"
3. Chá» 3-5 phÃºt Ä‘á»ƒ agent research
4. Xem káº¿t quáº£ 8 categories, download JSON
5. Tab "Chat With Philosopher" â†’ "Start Chat"
6. Thá»­ há»i: "Kant, can you explain your categorical imperative?"

### VÃ­ dá»¥ 2: Upload research cÃ³ sáºµn Ä‘á»ƒ chat

1. Download file máº«u: `research_socrates.json`
2. Tab "Chat With Philosopher" â†’ Upload file nÃ y
3. Chat vá»›i Socrates: "What is the meaning of 'know thyself'?"

### VÃ­ dá»¥ 3: Command line research

```bash
# Táº¡o script Ä‘Æ¡n giáº£n
cat > quick_research.py << 'EOF'
from research_agent.graph import get_default_research_graph
import json

philosopher = input("Enter philosopher name: ")
graph = get_default_research_graph()
result = graph.invoke({"philosopher_name": philosopher})

# Save result
filename = f"research_{philosopher.lower().replace(' ', '_')}.json"
with open(filename, 'w', encoding='utf-8') as f:
    json.dump(result, f, ensure_ascii=False, indent=2)
    
print(f"Research completed! Saved to {filename}")
EOF

python quick_research.py
```

## ğŸ› Troubleshooting

### âŒ Lá»—i thÆ°á»ng gáº·p

**1. ModuleNotFoundError**
```bash
# Äáº£m báº£o Ä‘Ã£ cÃ i Ä‘áº·t Ä‘áº§y Ä‘á»§
pip install -r requirements.txt
# Kiá»ƒm tra Python path
python -c "import sys; print(sys.path)"
```

**2. API Key errors**
```bash
# Kiá»ƒm tra .env file
cat .env
# Test API keys
python -c "
from dotenv import load_dotenv
import os
load_dotenv()
print('GROQ_API_KEY:', bool(os.getenv('GROQ_API_KEY')))
print('TAVILY_API_KEY:', bool(os.getenv('TAVILY_API_KEY')))
"
```

**3. Streamlit connection errors**
```bash
# Restart Streamlit
pkill -f streamlit
streamlit run main.py --server.port 8502  # Try different port
```

**4. Chat agent initialization fails**
```bash
# Kiá»ƒm tra chat dependencies
python -c "from chatAgent.processInformation import generate_roleplay_prompt_from_json_string; print('Chat module OK')"
```

**5. Database locked errors**
```bash
# XÃ³a chat checkpoints náº¿u bá»‹ corrupt  
rm chat_checkpoints.sqlite*
```

### ğŸ”§ Debug tips

```bash
# Cháº¡y vá»›i verbose logging
export LANGCHAIN_VERBOSE=true
streamlit run main.py

# Kiá»ƒm tra RAM usage (research cÃ³ thá»ƒ tá»‘n nhiá»u memory)
python -c "import psutil; print(f'RAM: {psutil.virtual_memory().percent}%')"
```

## ğŸ“‹ YÃªu cáº§u há»‡ thá»‘ng

### Minimum Requirements:
- **Python**: 3.9+
- **RAM**: 4GB+ (8GB+ khuyáº¿n khÃ­ch cho research lá»›n)  
- **Disk**: 1GB free space
- **Network**: Broadband internet (cho API calls)

### Recommended:
- **Python**: 3.10 hoáº·c 3.11
- **RAM**: 8GB+ 
- **CPU**: Multi-core processor
- **SSD**: Faster I/O cho database operations

## ğŸš€ Performance Tips

1. **Groq model selection**: `mixtral-8x7b-32768` cÃ¢n báº±ng tá»‘t tá»‘c Ä‘á»™/cháº¥t lÆ°á»£ng
2. **Tavily search results**: Giá»¯ á»Ÿ 5-8 results má»—i query Ä‘á»ƒ trÃ¡nh rate limit
3. **Research categories**: CÃ³ thá»ƒ comment bá»›t categories trong `state.py` náº¿u muá»‘n research nhanh hÆ¡n
4. **Chat history**: Database tá»± Ä‘á»™ng clean up, nhÆ°ng cÃ³ thá»ƒ xÃ³a `chat_checkpoints.sqlite*` náº¿u quÃ¡ lá»›n

## ğŸ¤ ÄÃ³ng gÃ³p

Contributions ráº¥t Ä‘Æ°á»£c hoan nghÃªnh! Má»™t sá»‘ Ã½ tÆ°á»Ÿng phÃ¡t triá»ƒn:

### ğŸ“‹ Roadmap
- [ ] **Multi-language support**: Má»Ÿ rá»™ng há»— trá»£ tiáº¿ng PhÃ¡p, Äá»©c, Trung, Nháº­t
- [ ] **Advanced search**: TÃ­ch há»£p Google Scholar, JSTOR
- [ ] **Audio chat**: Text-to-speech cho tráº£i nghiá»‡m tÆ°Æ¡ng tÃ¡c
- [ ] **Comparative analysis**: So sÃ¡nh 2 triáº¿t gia cÃ¹ng lÃºc
- [ ] **Export formats**: PDF, Word, LaTeX output  
- [ ] **Plugin system**: Cho phÃ©p custom research categories
- [ ] **Mobile app**: React Native hoáº·c Flutter version

### ğŸ”§ Technical Improvements  
- [ ] **Async processing**: Background research tasks
- [ ] **Caching**: Redis cache cho search results
- [ ] **Vector search**: Semantic search trong accumulated knowledge
- [ ] **RAG system**: Retrieval-augmented generation
- [ ] **Model fine-tuning**: Custom philosopher-specific models

### ğŸ’¡ Feature Ideas
- [ ] **Historical timeline**: Tá»± Ä‘á»™ng táº¡o timeline cuá»™c Ä‘á»i triáº¿t gia
- [ ] **Influence network**: Visualize má»‘i quan há»‡ giá»¯a cÃ¡c triáº¿t gia  
- [ ] **Debate mode**: Hai triáº¿t gia tranh luáº­n vá»›i nhau
- [ ] **Quiz generation**: Tá»± Ä‘á»™ng táº¡o cÃ¢u há»i test kiáº¿n thá»©c
- [ ] **Mind mapping**: Visual representation cá»§a tÆ° tÆ°á»Ÿng

## ğŸ“„ License & Credits

**License**: MIT License - Xem file LICENSE Ä‘á»ƒ biáº¿t chi tiáº¿t.

**Credits**:
- **LangChain & LangGraph**: Framework cá»‘t lÃµi
- **Groq**: Fast LLM inference  
- **Tavily**: Intelligent web search
- **Streamlit**: Beautiful web interface
- **OpenRouter**: Alternative LLM provider

## ğŸ“ Há»— trá»£

### ğŸ”— LiÃªn há»‡  
- **GitHub Issues**: [Táº¡o issue má»›i](https://github.com/your-repo/issues)
- **Discussion**: GitHub Discussions cho cÃ¢u há»i chung

### ğŸ“š Documentation Links
- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- [Groq API Docs](https://console.groq.com/docs)  
- [Tavily Search API](https://tavily.com/docs)
- [Streamlit Docs](https://docs.streamlit.io/)

### ğŸ†˜ Quick Help
```bash
# Health check script
python -c "
print('ğŸ” Checking system health...')
try:
    import langchain, langgraph, streamlit, groq
    print('âœ… All packages installed')
    
    from dotenv import load_dotenv
    import os
    load_dotenv()
    
    apis = {
        'GROQ_API_KEY': bool(os.getenv('GROQ_API_KEY')),
        'TAVILY_API_KEY': bool(os.getenv('TAVILY_API_KEY'))
    }
    
    for api, status in apis.items():
        print(f"{'âœ…' if status else 'âŒ'} {api}: {'SET' if status else 'MISSING'}")
        
    if all(apis.values()):
        print('ğŸ‰ System ready!')
    else:
        print('âš ï¸  Please set missing API keys in .env file')
        
except ImportError as e:
    print(f'âŒ Missing package: {e}')
    print('Run: pip install -r requirements.txt')
"
```

---

**âš ï¸ LÆ°u Ã½ quan trá»ng**: Há»‡ thá»‘ng nÃ y sá»­ dá»¥ng AI Ä‘á»ƒ tá»•ng há»£p thÃ´ng tin tá»« web. LuÃ´n kiá»ƒm tra vÃ  xÃ¡c minh thÃ´ng tin tá»« cÃ¡c nguá»“n há»c thuáº­t Ä‘Ã¡ng tin cáº­y trÆ°á»›c khi sá»­ dá»¥ng cho má»¥c Ä‘Ã­ch nghiÃªn cá»©u hoáº·c há»c táº­p nghiÃªm tÃºc.

**ğŸ“ Educational Use**: Project nÃ y Ä‘Æ°á»£c thiáº¿t káº¿ cho má»¥c Ä‘Ã­ch há»c táº­p vÃ  khÃ¡m phÃ¡ triáº¿t há»c. HÃ£y sá»­ dá»¥ng nhÆ° má»™t cÃ´ng cá»¥ há»— trá»£, khÃ´ng thay tháº¿ viá»‡c Ä‘á»c tÃ¡c pháº©m gá»‘c vÃ  nghiÃªn cá»©u há»c thuáº­t chuyÃªn sÃ¢u.
